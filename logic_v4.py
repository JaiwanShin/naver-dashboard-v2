"""
logic_v4.py - V4 ì „ìš© ë¡œì§ ëª¨ë“ˆ
ë„¤ì´ë²„ ì‡¼í•‘ ëª¨ë‹ˆí„°ë§ CSV ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìˆœìˆ˜ í•¨ìˆ˜ë“¤

ì´ ëª¨ë“ˆì€ UI(Streamlit)ì™€ ë¶„ë¦¬ëœ ë¡œì§ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
UIì—ì„œ @st.cache_data ë“±ì„ ì ìš©í•˜ì—¬ ìºì‹±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import re
import pandas as pd
import numpy as np
from typing import List, Tuple, Optional, Dict
from urllib.parse import urlparse


# =============================================================================
# [1] ì»¬ëŸ¼ ë§¤í•‘
# =============================================================================

def map_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì…ë ¥ CSV ì»¬ëŸ¼ì„ í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì •ê·œí™”í•œë‹¤.
    
    Args:
        df: ì›ë³¸ CSV DataFrame
        
    Returns:
        í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì •ê·œí™”ëœ DataFrame
        
    í‘œì¤€ ì»¬ëŸ¼:
        query, product_id, page_rank, product_name, brand, maker, price,
        category1, category2, category3, link, image_url, seller, mall_name
        
    ìœ ì‚¬ ì»¬ëŸ¼ ë§¤í•‘:
        - title -> product_name
        - image -> image_url
        - lprice/hprice -> price (lprice ìš°ì„ )
        - ì‡¼í•‘ëª°ëª… -> mall_name
    """
    df = df.copy()
    
    # ì»¬ëŸ¼ëª… ë§¤í•‘ í…Œì´ë¸” (ì†ŒìŠ¤ -> íƒ€ê²Ÿ)
    column_mapping = {
        # product_name í›„ë³´
        'title': 'product_name',
        'product_title': 'product_name',
        'ìƒí’ˆëª…': 'product_name',
        'ì œí’ˆëª…': 'product_name',
        
        # image_url í›„ë³´
        'image': 'image_url',
        'img_url': 'image_url',
        'thumbnail': 'image_url',
        'ì´ë¯¸ì§€': 'image_url',
        
        # price í›„ë³´
        'lprice': 'price',
        'hprice': 'price',  # lpriceê°€ ì—†ì„ ë•Œë§Œ
        'ê°€ê²©': 'price',
        'íŒë§¤ê°€': 'price',
        
        # mall_name í›„ë³´
        'ì‡¼í•‘ëª°ëª…': 'mall_name',
        'íŒë§¤ì²˜': 'mall_name',
        'shop_name': 'mall_name',
        'store_name': 'mall_name',
        
        # seller í›„ë³´
        'íŒë§¤ì': 'seller',
        'seller_name': 'seller',
        
        # ê¸°íƒ€
        'ê²€ìƒ‰ì–´': 'query',
        'keyword': 'query',
        'rank': 'page_rank',
        'ìˆœìœ„': 'page_rank',
    }
    
    # í‘œì¤€ ì»¬ëŸ¼ ëª©ë¡
    standard_columns = [
        'query', 'product_id', 'page_rank', 'product_name', 'brand', 'maker',
        'price', 'category1', 'category2', 'category3', 'link', 'image_url',
        'seller', 'mall_name'
    ]
    
    # ê¸°ì¡´ ì»¬ëŸ¼ëª… ì†Œë¬¸ì ë²„ì „ ìƒì„± (ë§¤ì¹­ìš©)
    existing_cols_lower = {col.lower().strip(): col for col in df.columns}
    
    # ë§¤í•‘ ì ìš©
    for source, target in column_mapping.items():
        source_lower = source.lower()
        if source_lower in existing_cols_lower and target not in df.columns:
            original_col = existing_cols_lower[source_lower]
            df = df.rename(columns={original_col: target})
    
    # ì´ë¯¸ í‘œì¤€ ì»¬ëŸ¼ëª…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€ (ëŒ€ì†Œë¬¸ì ì •ê·œí™”)
    for col in df.columns:
        col_lower = col.lower().strip()
        for std_col in standard_columns:
            if col_lower == std_col.lower() and col != std_col:
                df = df.rename(columns={col: std_col})
                break
    
    # ëˆ„ë½ëœ í‘œì¤€ ì»¬ëŸ¼ ìƒì„±
    for col in standard_columns:
        if col not in df.columns:
            df[col] = None
    
    # price ì»¬ëŸ¼ ìˆ«ì ë³€í™˜
    if 'price' in df.columns:
        df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0).astype(int)
    
    return df


# =============================================================================
# [2] íŒë§¤ì²˜ ì‹ë³„
# =============================================================================

def add_seller_fields(df: pd.DataFrame) -> pd.DataFrame:
    """
    seller/mall_name ì»¬ëŸ¼ì´ ë¹„ì–´ìˆìœ¼ë©´ linkì—ì„œ ë„ë©”ì¸ì„ ì¶”ì¶œí•˜ì—¬ ì±„ìš´ë‹¤.
    
    Args:
        df: map_columns() ì²˜ë¦¬ í›„ì˜ DataFrame
        
    Returns:
        seller/mall_nameì´ ì±„ì›Œì§„ DataFrame
        
    Notes:
        - link ì»¬ëŸ¼ì—ì„œ ë„ë©”ì¸ì„ ì¶”ì¶œí•˜ì—¬ mall_nameì— ì €ì¥
        - seller ì»¬ëŸ¼ì´ ë¹„ì–´ìˆìœ¼ë©´ mall_nameê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •
        - ì˜ˆ: https://smartstore.naver.com/xyz -> smartstore.naver.com
    """
    df = df.copy()
    
    def extract_domain(url: str) -> str:
        """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
        if pd.isna(url) or not url:
            return ''
        try:
            parsed = urlparse(str(url))
            return parsed.netloc or ''
        except Exception:
            return ''
    
    # mall_nameì´ ë¹„ì–´ìˆëŠ” ê²½ìš° linkì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
    if 'link' in df.columns:
        mask_empty_mall = df['mall_name'].isna() | (df['mall_name'].astype(str).str.strip() == '')
        df.loc[mask_empty_mall, 'mall_name'] = df.loc[mask_empty_mall, 'link'].apply(extract_domain)
    
    # sellerê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° mall_nameìœ¼ë¡œ ì±„ì›€
    mask_empty_seller = df['seller'].isna() | (df['seller'].astype(str).str.strip() == '')
    df.loc[mask_empty_seller, 'seller'] = df.loc[mask_empty_seller, 'mall_name']
    
    return df


# =============================================================================
# [3] ìš©ëŸ‰(ë§¤ìˆ˜) íŒŒì‹±
# =============================================================================

def parse_size_from_title(title: str) -> Optional[int]:
    """
    ìƒí’ˆëª…ì—ì„œ ìš©ëŸ‰(ë§¤ìˆ˜)ì„ íŒŒì‹±í•œë‹¤.
    
    Args:
        title: ìƒí’ˆëª… (ì˜ˆ: "ìº„í”„ ì¹´ë°íŒ¨ë“œ 70ë§¤", "100ë§¤ì… ëŒ€ìš©ëŸ‰")
        
    Returns:
        ë§¤ìˆ˜ (int) ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
        
    Examples:
        >>> parse_size_from_title("ìº„í”„ ì¹´ë°íŒ¨ë“œ 70ë§¤")
        70
        >>> parse_size_from_title("100ë§¤ì… ëŒ€ìš©ëŸ‰")
        100
        >>> parse_size_from_title("ìº„í”„ ì¹´ë°íŒ¨ë“œ")
        None
    """
    if pd.isna(title) or not title:
        return None
    
    # íŒ¨í„´: ìˆ«ì + "ë§¤" (+ ì˜µì…˜ìœ¼ë¡œ "ì…")
    # ì˜ˆ: 70ë§¤, 100ë§¤ì…, 60 ë§¤
    pattern = r'(\d+)\s*ë§¤(?:ì…)?'
    match = re.search(pattern, str(title))
    
    if match:
        return int(match.group(1))
    return None


def _apply_size_parsing(df: pd.DataFrame) -> pd.DataFrame:
    """
    DataFrameì— size_count ì»¬ëŸ¼ì„ ì¶”ê°€í•œë‹¤.
    
    Args:
        df: product_name ì»¬ëŸ¼ì´ ìˆëŠ” DataFrame
        
    Returns:
        size_count ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    df = df.copy()
    df['size_count'] = df['product_name'].apply(parse_size_from_title)
    return df


# =============================================================================
# [4] ì •í™• ë§¤ì¹­ í•„í„°
# =============================================================================

# ì œì™¸ íŒ¨í„´ ì •ì˜
EXCLUDE_PATTERNS = {
    'BUNDLE_FREE_GIFT': r'ì„¸íŠ¸|2ì¢…|3ì¢…|ê¸°íš|íŒ¨í‚¤ì§•|í•œì •|êµ¬ì„±|bundle|íŒ¨í‚¤ì§€|ì¦ì •|ì‚¬ì€í’ˆ|ì‡¼í•‘ë°±|ìŠ¤íƒ€ë²…ìŠ¤|ìƒí’ˆê¶Œ|ì¿ í°|êµ¬ë§¤ì‹œ',
    'MULTIPACK': r'1\+1|2ê°œ|3ê°œ|4ê°œ|[xX]2|2íŒ©|ë¬¶ìŒ|ë”ë¸”|ë“€ì˜¤|íŠ¸ë¦¬ì˜¤',
    'REFILL_SAMPLE': r'ë¦¬í•„|sample|ìƒ˜í”Œ|í…ŒìŠ¤í„°',
}


def filter_search_results(
    df: pd.DataFrame,
    query: str,
    include_variants: bool = False
) -> Tuple[pd.DataFrame, pd.DataFrame, Optional[int]]:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •í™• ë§¤ì¹­ í•„í„°ë§í•œë‹¤.
    
    Args:
        df: í‘œì¤€í™”ëœ DataFrame (map_columns í›„)
        query: ê²€ìƒ‰ì–´ (ì°¸ì¡°ìš©, ë¡œê¹…/ë””ë²„ê¹… ëª©ì )
        include_variants: Trueì´ë©´ NON_STANDARD_SIZEë„ í¬í•¨
        
    Returns:
        (df_kept, df_excluded, mode_size)
        - df_kept: í•„í„° í†µê³¼ ë°ì´í„°
        - df_excluded: ì œì™¸ ë°ì´í„° (excluded_reason ì»¬ëŸ¼ í¬í•¨)
        - mode_size: ëŒ€í‘œ ìš©ëŸ‰ (mode), ì—†ìœ¼ë©´ None
        
    í¬í•¨ ì¡°ê±´:
        - product_nameì— "ìº„í”„" AND ("ì¹´ë°íŒ¨ë“œ" ë˜ëŠ” "ì¹´ë° íŒ¨ë“œ") í¬í•¨
        - brandê°€ "Calmf"/"ìº„í”„"ì´ë©´ ê°€ì‚°ì  (ìš°ì„  í†µê³¼)
        
    ì œì™¸ ì¡°ê±´ (excluded_reason):
        - BUNDLE_FREE_GIFT: ì„¸íŠ¸/ì¦ì •í’ˆ ë“±
        - MULTIPACK: 1+1, 2ê°œ ë“±
        - OTHER_PRODUCT_COMBO: "+" í¬í•¨ (ì œí’ˆ ì¡°í•©)
        - REFILL_SAMPLE: ë¦¬í•„/ìƒ˜í”Œ
        - NON_STANDARD_SIZE: ëŒ€í‘œ ìš©ëŸ‰ ì™¸
    """
    df = df.copy()
    
    # size_count íŒŒì‹±
    df = _apply_size_parsing(df)
    
    # excluded_reason ì»¬ëŸ¼ ì´ˆê¸°í™”
    df['excluded_reason'] = ''
    
    # 1. í¬í•¨ ì¡°ê±´ ì²´í¬: product_nameì— "ìº„í”„" AND ("ì¹´ë°íŒ¨ë“œ" or "ì¹´ë° íŒ¨ë“œ")
    def check_include_condition(row) -> bool:
        product_name = str(row.get('product_name', '')).lower()
        brand = str(row.get('brand', '')).lower()
        
        # ë¸Œëœë“œê°€ ìº„í”„/calmfë©´ ìš°ì„  í†µê³¼
        if brand in ['ìº„í”„', 'calmf']:
            return True
        
        # product_name ì¡°ê±´
        has_calmf = 'ìº„í”„' in product_name
        has_calming_pad = 'ì¹´ë°íŒ¨ë“œ' in product_name or 'ì¹´ë° íŒ¨ë“œ' in product_name
        
        return has_calmf and has_calming_pad
    
    # í¬í•¨ ì¡°ê±´ ì ìš©
    include_mask = df.apply(check_include_condition, axis=1)
    df.loc[~include_mask, 'excluded_reason'] = 'NOT_MATCHING_PRODUCT'
    
    # 2. ì œì™¸ ì¡°ê±´ ì²´í¬ (í¬í•¨ ì¡°ê±´ í†µê³¼í•œ ê²ƒ ì¤‘ì—ì„œ)
    def check_exclude_patterns(product_name: str) -> str:
        """ì œì™¸ íŒ¨í„´ ë§¤ì¹­, ì²« ë²ˆì§¸ ë§¤ì¹­ëœ ì´ìœ  ë°˜í™˜"""
        if pd.isna(product_name):
            return ''
        
        name_lower = str(product_name).lower()
        
        # ê° íŒ¨í„´ ì²´í¬
        for reason, pattern in EXCLUDE_PATTERNS.items():
            if re.search(pattern, name_lower, re.IGNORECASE):
                return reason
        
        # OTHER_PRODUCT_COMBO: "+" í¬í•¨ ì²´í¬
        if '+' in name_lower:
            # ë‹¨ìˆœ "+" í¬í•¨ì´ë©´ ì œì™¸ (ì œí’ˆëª… + ë‹¤ë¥¸ì œí’ˆ í˜•íƒœ)
            return 'OTHER_PRODUCT_COMBO'
        
        return ''
    
    # í¬í•¨ ì¡°ê±´ í†µê³¼í•œ í–‰ì— ëŒ€í•´ ì œì™¸ íŒ¨í„´ ì²´í¬
    passed_include = df['excluded_reason'] == ''
    for idx in df[passed_include].index:
        product_name = df.loc[idx, 'product_name']
        exclude_reason = check_exclude_patterns(product_name)
        if exclude_reason:
            df.loc[idx, 'excluded_reason'] = exclude_reason
    
    # 3. ëŒ€í‘œ ìš©ëŸ‰(mode) ê³„ì‚° - í•„í„° í†µê³¼í•œ ë°ì´í„° ê¸°ì¤€
    current_kept = df[df['excluded_reason'] == '']
    mode_size = None
    
    if not current_kept.empty:
        valid_sizes = current_kept['size_count'].dropna()
        if len(valid_sizes) > 0:
            # mode ê³„ì‚° (ê°€ì¥ ë¹ˆë²ˆí•œ ê°’)
            mode_result = valid_sizes.mode()
            if len(mode_result) > 0:
                mode_size = int(mode_result.iloc[0])
    
    # 4. NON_STANDARD_SIZE ì²˜ë¦¬
    if mode_size is not None:
        # size_countê°€ modeì™€ ë‹¤ë¥¸ ê²½ìš° (Noneë„ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ ì·¨ê¸‰)
        for idx in df[df['excluded_reason'] == ''].index:
            size = df.loc[idx, 'size_count']
            if pd.isna(size) or int(size) != mode_size:
                df.loc[idx, 'excluded_reason'] = 'NON_STANDARD_SIZE'
    
    # 5. include_variants=Trueì´ë©´ NON_STANDARD_SIZE í•´ì œ
    if include_variants:
        df.loc[df['excluded_reason'] == 'NON_STANDARD_SIZE', 'excluded_reason'] = ''
    
    # 6. ê²°ê³¼ ë¶„ë¦¬
    df_kept = df[df['excluded_reason'] == ''].copy()
    df_excluded = df[df['excluded_reason'] != ''].copy()
    
    return df_kept, df_excluded, mode_size


# =============================================================================
# [5] ì´ìƒì¹˜ íƒì§€ (IQR)
# =============================================================================

def detect_outliers_iqr(
    df: pd.DataFrame,
    group_cols: List[str] = None,
    use_aux: bool = False,
    aux_pct: float = 50.0
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    IQR ë°©ì‹ìœ¼ë¡œ ê°€ê²© ì´ìƒì¹˜ë¥¼ íƒì§€í•œë‹¤.
    
    Args:
        df: í•„í„° ì™„ë£Œëœ ë°ì´í„° (df_kept)
        group_cols: ê·¸ë£¹í™” ê¸°ì¤€ ì»¬ëŸ¼ (ê¸°ë³¸: ['query'])
        use_aux: ë³´ì¡° ê·œì¹™ ì ìš© ì—¬ë¶€
        aux_pct: ë³´ì¡° ê·œì¹™ ì„ê³„ê°’ (%, ê¸°ë³¸ 50)
        
    Returns:
        (df_before_outlier, df_inliers, df_outliers, stats_df)
        - df_before_outlier: outlier_flag, deviation_pct ì»¬ëŸ¼ í¬í•¨
        - df_inliers: ì •ìƒ ë°ì´í„° (outlier_flag=False)
        - df_outliers: ì´ìƒì¹˜ ë°ì´í„° (outlier_flag=True)
        - stats_df: ê·¸ë£¹ë³„ í†µê³„ (Q1, Q3, IQR, lower, upper, median, outlier_count)
        
    Notes:
        - IQR ë°©ì‹: lower = Q1 - 1.5*IQR, upper = Q3 + 1.5*IQR
        - deviation_pct = (price - median) / median * 100
        - use_aux=True: abs(deviation_pct) >= aux_pct ë„ ì´ìƒì¹˜ë¡œ ì¶”ê°€
    """
    if group_cols is None:
        group_cols = ['query']
    
    df = df.copy()
    
    # price ì»¬ëŸ¼ í™•ì¸
    if 'price' not in df.columns or df.empty:
        # ë¹ˆ ê²°ê³¼ ë°˜í™˜
        df['outlier_flag'] = False
        df['deviation_pct'] = 0.0
        empty_stats = pd.DataFrame(columns=['Q1', 'Q3', 'IQR', 'lower', 'upper', 'median', 'outlier_count'])
        return df, df, df.iloc[0:0], empty_stats
    
    # ê°€ê²©ì´ 0ë³´ë‹¤ í° ë°ì´í„°ë§Œ ë¶„ì„
    df = df[df['price'] > 0].copy()
    
    if df.empty:
        df['outlier_flag'] = False
        df['deviation_pct'] = 0.0
        empty_stats = pd.DataFrame(columns=['Q1', 'Q3', 'IQR', 'lower', 'upper', 'median', 'outlier_count'])
        return df, df, df.iloc[0:0], empty_stats
    
    # ìœ íš¨í•œ ê·¸ë£¹ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    valid_group_cols = [col for col in group_cols if col in df.columns]
    
    # ê·¸ë£¹ë³„ í†µê³„ ê³„ì‚° í•¨ìˆ˜
    def compute_stats(group_df: pd.DataFrame) -> Dict:
        prices = group_df['price']
        q1 = prices.quantile(0.25)
        q3 = prices.quantile(0.75)
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        median = prices.median()
        return {
            'Q1': q1,
            'Q3': q3,
            'IQR': iqr,
            'lower': lower,
            'upper': upper,
            'median': median
        }
    
    # ê·¸ë£¹ì´ ì—†ê±°ë‚˜ ì „ì²´ ê¸°ì¤€ì¸ ê²½ìš°
    if not valid_group_cols:
        stats = compute_stats(df)
        df['_lower'] = stats['lower']
        df['_upper'] = stats['upper']
        df['_median'] = stats['median']
        stats_list = [stats]
        stats_df = pd.DataFrame(stats_list)
    else:
        # ê·¸ë£¹ë³„ í†µê³„ ê³„ì‚°
        stats_dict = {}
        for name, group in df.groupby(valid_group_cols, dropna=False):
            key = name if isinstance(name, tuple) else (name,)
            stats_dict[key] = compute_stats(group)
        
        # ê° í–‰ì— í†µê³„ ì •ë³´ ë§¤í•‘
        def get_group_key(row):
            return tuple(row[col] for col in valid_group_cols)
        
        df['_lower'] = df.apply(lambda row: stats_dict.get(get_group_key(row), {}).get('lower', 0), axis=1)
        df['_upper'] = df.apply(lambda row: stats_dict.get(get_group_key(row), {}).get('upper', float('inf')), axis=1)
        df['_median'] = df.apply(lambda row: stats_dict.get(get_group_key(row), {}).get('median', 0), axis=1)
        
        # stats_df ìƒì„±
        stats_list = []
        for key, stats in stats_dict.items():
            row = dict(zip(valid_group_cols, key))
            row.update(stats)
            stats_list.append(row)
        stats_df = pd.DataFrame(stats_list)
    
    # deviation_pct ê³„ì‚°
    df['deviation_pct'] = np.where(
        df['_median'] != 0,
        (df['price'] - df['_median']) / df['_median'] * 100,
        0.0
    )
    
    # outlier_flag ê³„ì‚° (IQR ê¸°ì¤€)
    df['outlier_flag'] = (df['price'] < df['_lower']) | (df['price'] > df['_upper'])
    
    # ë³´ì¡° ê·œì¹™ ì ìš©
    if use_aux:
        aux_outlier = np.abs(df['deviation_pct']) >= aux_pct
        df['outlier_flag'] = df['outlier_flag'] | aux_outlier
    
    # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    df_before_outlier = df.drop(columns=['_lower', '_upper', '_median'])
    
    # outlier_count ì¶”ê°€
    if valid_group_cols:
        outlier_counts = df_before_outlier[df_before_outlier['outlier_flag']].groupby(
            valid_group_cols, dropna=False
        ).size().reset_index(name='outlier_count')
        stats_df = stats_df.merge(outlier_counts, on=valid_group_cols, how='left')
        stats_df['outlier_count'] = stats_df['outlier_count'].fillna(0).astype(int)
    else:
        stats_df['outlier_count'] = int(df_before_outlier['outlier_flag'].sum())
    
    # ê²°ê³¼ ë¶„ë¦¬
    df_inliers = df_before_outlier[~df_before_outlier['outlier_flag']].copy()
    df_outliers = df_before_outlier[df_before_outlier['outlier_flag']].copy()
    
    return df_before_outlier, df_inliers, df_outliers, stats_df


# =============================================================================
# [5.5] ì´ìƒì¹˜ íƒì§€ (Quantile Cap - Q2.5)
# =============================================================================

# ê¸°ë³¸ ìƒí•œ ë¶„ìœ„ìˆ˜ (Q3 = 0.75)
DEFAULT_UPPER_QUANTILE = 0.75

def detect_outliers_quantile(
    df: pd.DataFrame,
    group_cols: List[str] = None,
    upper_quantile: float = DEFAULT_UPPER_QUANTILE,
    use_aux: bool = False,
    aux_pct: float = 50.0
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    Quantile Cap ë°©ì‹ìœ¼ë¡œ ê°€ê²© ì´ìƒì¹˜ë¥¼ íƒì§€í•œë‹¤.
    
    Args:
        df: í•„í„° ì™„ë£Œëœ ë°ì´í„° (df_kept)
        group_cols: ê·¸ë£¹í™” ê¸°ì¤€ ì»¬ëŸ¼ (ê¸°ë³¸: ['query'])
        upper_quantile: ìƒí•œ ë¶„ìœ„ìˆ˜ (ê¸°ë³¸ 0.625 = Q2.5)
        use_aux: ë³´ì¡° ê·œì¹™ ì ìš© ì—¬ë¶€
        aux_pct: ë³´ì¡° ê·œì¹™ ì„ê³„ê°’ (%, ê¸°ë³¸ 50)
        
    Returns:
        (df_before_outlier, df_inliers, df_outliers, stats_df)
        - df_before_outlier: outlier_flag, deviation_pct, bound_lower, bound_upper ì»¬ëŸ¼ í¬í•¨
        - df_inliers: ì •ìƒ ë°ì´í„° (outlier_flag=False)
        - df_outliers: ì´ìƒì¹˜ ë°ì´í„° (outlier_flag=True)
        - stats_df: ê·¸ë£¹ë³„ í†µê³„ (Q1, upper_q, lower, upper, median, outlier_count, method)
        
    Notes:
        - lower = Q1 (IQR ê¸°ë°˜ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
        - upper = quantile(upper_quantile) (ê¸°ë³¸ 0.625 = Q2.5)
        - Q2.5ëŠ” median(0.5)ê³¼ Q3(0.75) ì‚¬ì´ì˜ ì¤‘ê°„ê°’ìœ¼ë¡œ, ë” íƒ€ì´íŠ¸í•œ ìƒí•œ
    """
    if group_cols is None:
        group_cols = ['query']
    
    df = df.copy()
    
    # price ì»¬ëŸ¼ í™•ì¸
    if 'price' not in df.columns or df.empty:
        df['outlier_flag'] = False
        df['deviation_pct'] = 0.0
        df['bound_lower'] = 0.0
        df['bound_upper'] = float('inf')
        empty_stats = pd.DataFrame(columns=['Q1', 'upper_q', 'lower', 'upper', 'median', 'outlier_count', 'method'])
        return df, df, df.iloc[0:0], empty_stats
    
    # ê°€ê²©ì´ 0ë³´ë‹¤ í° ë°ì´í„°ë§Œ ë¶„ì„
    df = df[df['price'] > 0].copy()
    
    if df.empty:
        df['outlier_flag'] = False
        df['deviation_pct'] = 0.0
        df['bound_lower'] = 0.0
        df['bound_upper'] = float('inf')
        empty_stats = pd.DataFrame(columns=['Q1', 'upper_q', 'lower', 'upper', 'median', 'outlier_count', 'method'])
        return df, df, df.iloc[0:0], empty_stats
    
    # ìœ íš¨í•œ ê·¸ë£¹ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    valid_group_cols = [col for col in group_cols if col in df.columns]
    
    # ê·¸ë£¹ë³„ í†µê³„ ê³„ì‚° í•¨ìˆ˜
    def compute_stats(group_df: pd.DataFrame) -> Dict:
        prices = group_df['price']
        q1 = prices.quantile(0.25)
        upper_q_val = prices.quantile(upper_quantile)
        median = prices.median()
        # lowerëŠ” Q1 ìœ ì§€ (ê¸°ì¡´ IQR lowerì™€ ë™ì¼ ë¡œì§)
        lower = q1
        # upperëŠ” Q2.5 (ë” íƒ€ì´íŠ¸í•œ ìƒí•œ)
        upper = upper_q_val
        return {
            'Q1': q1,
            'upper_q': upper_q_val,
            'lower': lower,
            'upper': upper,
            'median': median,
            'method': f'Q{upper_quantile}'
        }
    
    # ê·¸ë£¹ì´ ì—†ê±°ë‚˜ ì „ì²´ ê¸°ì¤€ì¸ ê²½ìš°
    if not valid_group_cols:
        stats = compute_stats(df)
        df['bound_lower'] = stats['lower']
        df['bound_upper'] = stats['upper']
        df['_median'] = stats['median']
        stats_list = [stats]
        stats_df = pd.DataFrame(stats_list)
    else:
        # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ í†µê³„ ê³„ì‚° (ê·¸ë£¹ë³„ ëŒ€ì‹  ì „ì²´ë¡œ ê³„ì‚°)
        # queryê°€ Noneì¸ ê²½ìš°ê°€ ë§ì•„ì„œ ì „ì²´ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        stats = compute_stats(df)
        df['bound_lower'] = stats['lower']
        df['bound_upper'] = stats['upper']
        df['_median'] = stats['median']
        stats_list = [stats]
        stats_df = pd.DataFrame(stats_list)
    
    # deviation_pct ê³„ì‚°
    df['deviation_pct'] = np.where(
        df['_median'] != 0,
        (df['price'] - df['_median']) / df['_median'] * 100,
        0.0
    )
    
    # outlier_flag ê³„ì‚° (ì§ì ‘ bound ì»¬ëŸ¼ê³¼ ë¹„êµ)
    lower_bound = df['bound_lower'].iloc[0] if len(df) > 0 else 0
    upper_bound = df['bound_upper'].iloc[0] if len(df) > 0 else float('inf')
    
    df['outlier_flag'] = (df['price'] < lower_bound) | (df['price'] > upper_bound)
    
    # ë³´ì¡° ê·œì¹™ ì ìš©
    if use_aux:
        aux_outlier = np.abs(df['deviation_pct']) >= aux_pct
        df['outlier_flag'] = df['outlier_flag'] | aux_outlier
    
    # ì„ì‹œ ì»¬ëŸ¼ ì œê±° (_medianë§Œ)
    df_before_outlier = df.drop(columns=['_median'])
    
    # outlier_count ê³„ì‚°
    stats_df['outlier_count'] = int(df_before_outlier['outlier_flag'].sum())
    
    # ê²°ê³¼ ë¶„ë¦¬ - ì§ì ‘ ê°€ê²© ë²”ìœ„ë¡œ í•„í„°ë§
    df_inliers = df_before_outlier[
        (df_before_outlier['price'] >= lower_bound) & 
        (df_before_outlier['price'] <= upper_bound)
    ].copy()
    
    # ë³´ì¡° ê·œì¹™ ì ìš©ëœ ê²½ìš° ì¶”ê°€ í•„í„°ë§
    if use_aux:
        df_inliers = df_inliers[np.abs(df_inliers['deviation_pct']) < aux_pct].copy()
    
    df_outliers = df_before_outlier[df_before_outlier['outlier_flag']].copy()
    
    return df_before_outlier, df_inliers, df_outliers, stats_df


# =============================================================================
# [6] íŒë§¤ì²˜ë³„ ì´ìƒì¹˜ ìš”ì•½
# =============================================================================


def build_seller_outlier_summary(df_before_outlier: pd.DataFrame) -> pd.DataFrame:
    """
    íŒë§¤ì²˜ë³„ ì´ìƒì¹˜ ìš”ì•½ í†µê³„ë¥¼ ìƒì„±í•œë‹¤.
    
    Args:
        df_before_outlier: detect_outliers_iqr()ì˜ ì²« ë²ˆì§¸ ë°˜í™˜ê°’
                          (outlier_flag, deviation_pct ì»¬ëŸ¼ í¬í•¨)
        
    Returns:
        seller_summary_df: íŒë§¤ì²˜ë³„ ìš”ì•½ í†µê³„
        
    Columns:
        - seller (ë˜ëŠ” mall_name): íŒë§¤ì²˜
        - total_count: ì´ ìƒí’ˆ ìˆ˜
        - outlier_count: ì´ìƒì¹˜ ìƒí’ˆ ìˆ˜
        - outlier_rate: ì´ìƒì¹˜ ë¹„ìœ¨ (%)
        - mean_deviation_pct: í‰ê·  í¸ì°¨ (%)
    """
    df = df_before_outlier.copy()
    
    # ê·¸ë£¹ ê¸°ì¤€ ê²°ì •: seller ìš°ì„ , ì—†ìœ¼ë©´ mall_name
    if 'seller' in df.columns and df['seller'].notna().any() and (df['seller'].astype(str).str.strip() != '').any():
        group_col = 'seller'
    elif 'mall_name' in df.columns:
        group_col = 'mall_name'
    else:
        # ê·¸ë£¹ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame(columns=['seller', 'total_count', 'outlier_count', 'outlier_rate', 'mean_deviation_pct'])
    
    # ë¹ˆ ê°’ ì²˜ë¦¬
    df = df[df[group_col].notna() & (df[group_col].astype(str).str.strip() != '')].copy()
    
    if df.empty:
        return pd.DataFrame(columns=['seller', 'total_count', 'outlier_count', 'outlier_rate', 'mean_deviation_pct'])
    
    # ê·¸ë£¹ë³„ ì§‘ê³„
    summary = df.groupby(group_col, dropna=False).agg(
        total_count=('outlier_flag', 'count'),
        outlier_count=('outlier_flag', 'sum'),
        mean_deviation_pct=('deviation_pct', 'mean')
    ).reset_index()
    
    # outlier_rate ê³„ì‚°
    summary['outlier_rate'] = (summary['outlier_count'] / summary['total_count'] * 100).round(2)
    summary['mean_deviation_pct'] = summary['mean_deviation_pct'].round(2)
    
    # ì»¬ëŸ¼ëª… ì •ê·œí™”
    summary = summary.rename(columns={group_col: 'seller'})
    
    # ì •ë ¬: ì´ìƒì¹˜ ë¹„ìœ¨ ë†’ì€ ìˆœ
    summary = summary.sort_values('outlier_rate', ascending=False).reset_index(drop=True)
    
    return summary


# =============================================================================
# UI í˜¸ì¶œ ì˜ˆì‹œ ì½”ë“œ
# =============================================================================

"""
# ============================================
# Streamlit UIì—ì„œ í˜¸ì¶œí•˜ëŠ” ì˜ˆì‹œ ì½”ë“œ
# ============================================

import streamlit as st
import pandas as pd
from logic_v4 import (
    map_columns,
    add_seller_fields,
    filter_search_results,
    detect_outliers_iqr,
    build_seller_outlier_summary
)

# ìºì‹±ëœ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
@st.cache_data
def process_csv_data(uploaded_file, query: str, include_variants: bool, use_aux: bool, aux_pct: float):
    # 1. CSV ë¡œë“œ
    df_raw = pd.read_csv(uploaded_file)
    
    # 2. ì»¬ëŸ¼ ë§¤í•‘
    df_mapped = map_columns(df_raw)
    
    # 3. íŒë§¤ì²˜ ì‹ë³„
    df_with_seller = add_seller_fields(df_mapped)
    
    # 4. ì •í™• ë§¤ì¹­ í•„í„°
    df_kept, df_excluded, mode_size = filter_search_results(
        df_with_seller, 
        query=query, 
        include_variants=include_variants
    )
    
    # 5. ì´ìƒì¹˜ íƒì§€
    df_before_outlier, df_inliers, df_outliers, stats_df = detect_outliers_iqr(
        df_kept,
        group_cols=['query'],
        use_aux=use_aux,
        aux_pct=aux_pct
    )
    
    # 6. íŒë§¤ì²˜ë³„ ìš”ì•½
    seller_summary = build_seller_outlier_summary(df_before_outlier)
    
    return {
        'df_kept': df_kept,
        'df_excluded': df_excluded,
        'mode_size': mode_size,
        'df_before_outlier': df_before_outlier,
        'df_inliers': df_inliers,
        'df_outliers': df_outliers,
        'stats_df': stats_df,
        'seller_summary': seller_summary
    }


# Streamlit ì‚¬ì´ë“œë°” ì„¤ì • ì˜ˆì‹œ
with st.sidebar:
    include_variants = st.checkbox("ìš©ëŸ‰ ë³€í˜• í¬í•¨", value=False)
    use_aux = st.checkbox("ë³´ì¡° ì´ìƒì¹˜ ê·œì¹™ ì‚¬ìš©", value=False)
    aux_pct = st.slider("ë³´ì¡° ê·œì¹™ ì„ê³„ê°’ (%)", 10, 100, 50)

# íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬
uploaded_file = st.file_uploader("CSV ì—…ë¡œë“œ", type="csv")
if uploaded_file:
    results = process_csv_data(
        uploaded_file,
        query="ìº„í”„ ì¹´ë°íŒ¨ë“œ",
        include_variants=include_variants,
        use_aux=use_aux,
        aux_pct=aux_pct
    )
    
    # Expander 1: í•„í„°ë§ëœ ë°ì´í„°
    with st.expander("âœ… í•„í„° í†µê³¼ ë°ì´í„°", expanded=True):
        st.info(f"ëŒ€í‘œ ìš©ëŸ‰: {results['mode_size']}ë§¤")
        st.dataframe(results['df_kept'])
    
    # Expander 2: ì œì™¸ëœ ë°ì´í„°
    with st.expander("âŒ ì œì™¸ëœ ë°ì´í„°"):
        st.dataframe(results['df_excluded'])
    
    # Expander 3: ì´ìƒì¹˜ ë¶„ì„
    with st.expander("ğŸ“Š ì´ìƒì¹˜ ë¶„ì„"):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì •ìƒ ìƒí’ˆ", len(results['df_inliers']))
        with col2:
            st.metric("ì´ìƒì¹˜ ìƒí’ˆ", len(results['df_outliers']))
        st.dataframe(results['stats_df'])
    
    # Expander 4: íŒë§¤ì²˜ ìš”ì•½
    with st.expander("ğŸª íŒë§¤ì²˜ë³„ ì´ìƒì¹˜ ìš”ì•½"):
        st.dataframe(results['seller_summary'])
"""
